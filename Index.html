<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <title>Stickman – Android</title>
  <style>
    *,body{margin:0;height:100%;background:#000;color:#0f0;overflow:hidden;font-family:Roboto,sans-serif}
    video,canvas{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover}
    #status{position:absolute;top:8px;left:8px;font-size:18px;z-index:10}
    #flip{position:absolute;bottom:15px;right:15px;background:#222;color:#fff;border:none;padding:10px 18px;border-radius:24px;font-size:16px;z-index:20}
  </style>
</head>
<body>
  <div id="status">Loading…</div>
  <canvas id="c"></canvas>
  <video id="v" autoplay muted playsinline></video>
  <button id="flip">Flip cam</button>

  <script type="module">
    import {PoseLandmarker,FilesetResolver} from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

    const v=document.getElementById("v"), c=document.getElementById("c"), ctx=c.getContext("2d"), s=document.getElementById("status"), b=document.getElementById("flip");
    let facing="user";  // "user" = selfie, "environment" = back

    function resize(){c.width=innerWidth; c.height=innerHeight}
    addEventListener("resize",resize); resize();

    async function cam(){
      const stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:facing}});
      v.srcObject=stream;
      return v.play();
    }
    b.onclick=async()=>{facing=facing==="user"?"environment":"user"; v.srcObject.getTracks().forEach(t=>t.stop()); await cam();};

    const f=await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
    const p=await PoseLandmarker.createFromOptions(f,{
      baseOptions:{modelAssetPath:"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",delegate:"GPU"},
      runningMode:"VIDEO",numPoses:1
    });

    function draw(l){
      ctx.clearRect(0,0,c.width,c.height);
      const sc=Math.min(c.width/v.videoWidth,c.height/v.videoHeight);
      const ox=(c.width-v.videoWidth*sc)/2, oy=(c.height-v.videoHeight*sc)/2;
      const pt=i=>({x:ox+l[i].x*v.videoWidth*sc, y:oy+l[i].y*v.videoHeight*sc});
      const bones=[[11,12],[11,13],[13,15],[15,17],[15,19],[15,21],[17,19],[12,14],[14,16],[16,18],[16,20],[16,22],[18,20],[11,23],[12,24],[23,24],[23,25],[25,27],[27,29],[27,31],[24,26],[26,28],[28,30],[28,32],[30,32]];
      ctx.strokeStyle="cyan"; ctx.lineWidth=Math.max(2,sc*4); ctx.lineCap="round";
      for(const [a,b] of bones){const A=pt(a),B=pt(b); ctx.beginPath(); ctx.moveTo(A.x,A.y); ctx.lineTo(B.x,B.y); ctx.stroke()}
      ctx.fillStyle="white";
      for(let i=0;i<l.length;i++){const P=pt(i); ctx.beginPath(); ctx.arc(P.x,P.y,Math.max(3,sc*5),0,Math.PI*2); ctx.fill()}
    }

    let t0=0;
    async function loop(tm){
      if(tm-t0>30){
        t0=tm;
        const r=await p.detectForVideo(v,performance.now());
        if(r.landmarks.length){draw(r.landmarks[0]); s.textContent="Tracking…";}
        else{s.textContent="No body detected";}
      }
      requestAnimationFrame(loop);
    }

    await cam();
    v.addEventListener("loadedmetadata",()=>requestAnimationFrame(loop));
  </script>
</body>
</html>
